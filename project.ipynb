{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://cmind.intern%40gmail.com:****@charlesyin.pkgs.visualstudio.com/Cmind%20Inc/_packaging/Cmind-internal-python-packages/pypi/simple/\n",
      "Requirement already satisfied: numpy in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: scipy in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (1.14.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (1.5.1)\n",
      "Requirement already satisfied: mne in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (1.9.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: decorator in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from mne) (5.1.1)\n",
      "Requirement already satisfied: jinja2 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from mne) (3.1.4)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from mne) (0.4)\n",
      "Requirement already satisfied: matplotlib>=3.6 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from mne) (3.9.0)\n",
      "Requirement already satisfied: packaging in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from mne) (24.1)\n",
      "Requirement already satisfied: pooch>=1.5 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from mne) (1.8.2)\n",
      "Requirement already satisfied: tqdm in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from mne) (4.66.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from matplotlib>=3.6->mne) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from matplotlib>=3.6->mne) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from matplotlib>=3.6->mne) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from matplotlib>=3.6->mne) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from matplotlib>=3.6->mne) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from matplotlib>=3.6->mne) (2.9.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from pooch>=1.5->mne) (4.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from pooch>=1.5->mne) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from jinja2->mne) (2.1.5)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sherry/miniconda3/envs/earnings_transcript_scraping/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.8.30)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy scipy scikit-learn mne \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape of train_cnt: (17792, 3000)\n"
     ]
    }
   ],
   "source": [
    "train_cnt_file = \"train/Competition_train_cnt.txt\"\n",
    "train_lab_file = \"train/Competition_train_lab.txt\"\n",
    "\n",
    "train_cnt = np.loadtxt(train_cnt_file)\n",
    "Y_train = np.loadtxt(train_lab_file)\n",
    "\n",
    "print(\"Raw shape of train_cnt:\", train_cnt.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train final shape: (278, 64, 3000)\n",
      "Y_train shape: (278,)\n"
     ]
    }
   ],
   "source": [
    "n_trials_train = 278\n",
    "n_channels = 64\n",
    "n_samples = 3000\n",
    "\n",
    "X_train = train_cnt.reshape(n_trials_train, n_channels, n_samples)\n",
    "\n",
    "print(\"X_train final shape:\", X_train.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape of test_cnt: (6400, 3000)\n"
     ]
    }
   ],
   "source": [
    "test_file = \"test.txt\"\n",
    "test_label_file = \"test_label.txt\"\n",
    "\n",
    "test_cnt = np.loadtxt(test_file)\n",
    "Y_test = np.loadtxt(test_label_file)\n",
    "\n",
    "print(\"Raw shape of test_cnt:\", test_cnt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test final shape: (100, 64, 3000)\n"
     ]
    }
   ],
   "source": [
    "n_trials_test = 100\n",
    "X_test = test_cnt.reshape(n_trials_test, n_channels, n_samples)\n",
    "\n",
    "print(\"test final shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Shape: (222, 64, 3000) (222,)\n",
      "Validation Set Shape: (56, 64, 3000) (56,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train Set Shape:\", X_train.shape, Y_train.shape)\n",
    "print(\"Validation Set Shape:\", X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_filter(data, lowcut=8, highcut=30, fs=1000, order=5):\n",
    "    \"\"\"\n",
    "    Apply a bandpass filter to the input data.\n",
    "\n",
    "    Parameters:\n",
    "        data (ndarray): EEG/ECoG data of shape (trials, channels, samples)\n",
    "        lowcut (float): Lower cutoff frequency (default: 8 Hz)\n",
    "        highcut (float): Upper cutoff frequency (default: 30 Hz)\n",
    "        fs (int): Sampling frequency (default: 1000 Hz)\n",
    "        order (int): Order of the filter (default: 5)\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Filtered data (same shape as input)\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "\n",
    "    filtered_data = lfilter(b, a, data, axis=-1)\n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filt = bandpass_filter(X_train)\n",
    "X_val_filt = bandpass_filter(X_val)\n",
    "X_test_filt = bandpass_filter(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_covariance(trial_data):\n",
    "    \"\"\"\n",
    "    Compute the covariance matrix for a given trial.\n",
    "    \n",
    "    Parameters:\n",
    "        trial_data (ndarray): Shape (channels, samples)\n",
    "    \n",
    "    Returns:\n",
    "        ndarray: Covariance matrix (channels x channels)\n",
    "    \"\"\"\n",
    "    return np.cov(trial_data)\n",
    "\n",
    "def csp_fit(X, y, n_components=3):\n",
    "    \"\"\"\n",
    "    Fit CSP spatial filters.\n",
    "\n",
    "    Parameters:\n",
    "        X (ndarray): Shape (trials, channels, samples)\n",
    "        y (ndarray): Labels (-1 or 1), shape (trials,)\n",
    "        n_components (int): Number of CSP components to retain per class\n",
    "\n",
    "    Returns:\n",
    "        ndarray: CSP spatial filters (channels, 2 * n_components)\n",
    "    \"\"\"\n",
    "\n",
    "    X_class1 = X[y == -1]\n",
    "    X_class2 = X[y == 1]\n",
    "\n",
    "    cov_class1 = np.mean([compute_covariance(x) for x in X_class1], axis=0)\n",
    "    cov_class2 = np.mean([compute_covariance(x) for x in X_class2], axis=0)\n",
    "\n",
    "    from scipy.linalg import eigh\n",
    "    w, v = eigh(cov_class1, cov_class2)\n",
    "\n",
    "    idx = np.argsort(w)[::-1]\n",
    "    v = v[:, idx]\n",
    "    filters = np.hstack([v[:, :n_components], v[:, -n_components:]])\n",
    "    \n",
    "    return filters\n",
    "\n",
    "def csp_transform(X, filters):\n",
    "    \"\"\"\n",
    "    Apply CSP transformation to extract log-variance features.\n",
    "\n",
    "    Parameters:\n",
    "        X (ndarray): Shape (trials, channels, samples)\n",
    "        filters (ndarray): CSP spatial filters (channels, 2*n_components)\n",
    "\n",
    "    Returns:\n",
    "        ndarray: CSP features (trials, 2*n_components)\n",
    "    \"\"\"\n",
    "    n_trials, _, _ = X.shape\n",
    "    n_filters = filters.shape[1]\n",
    "    features = np.zeros((n_trials, n_filters))\n",
    "\n",
    "    for i in range(n_trials):\n",
    "        projected = filters.T @ X[i] \n",
    "        var = np.var(projected, axis=1)\n",
    "        features[i, :] = np.log(var)\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8929\n"
     ]
    }
   ],
   "source": [
    "csp_filters = csp_fit(X_train_filt, Y_train, n_components=3)\n",
    "\n",
    "X_train_csp = csp_transform(X_train_filt, csp_filters)\n",
    "X_val_csp = csp_transform(X_val_filt, csp_filters)\n",
    "X_test_csp = csp_transform(X_test_filt, csp_filters)\n",
    "\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(X_train_csp, Y_train)\n",
    "\n",
    "pred_val = clf.predict(X_val_csp)\n",
    "acc_val = accuracy_score(Y_val, pred_val)\n",
    "print(f\"Validation Accuracy: {acc_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Adaptation Test Accuracy: 0.7600\n",
      "Confusion Matrix (No Adaptation):\n",
      "[[50  0]\n",
      " [24 26]]\n"
     ]
    }
   ],
   "source": [
    "pred_noadapt = clf.predict(X_test_csp)\n",
    "\n",
    "acc_noadapt = accuracy_score(Y_test, pred_noadapt)\n",
    "print(f\"No Adaptation Test Accuracy: {acc_noadapt:.4f}\")\n",
    "\n",
    "print(\"Confusion Matrix (No Adaptation):\")\n",
    "print(confusion_matrix(Y_test, pred_noadapt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define frequency bands (e.g., 4-8 Hz, 8-12 Hz, etc.)\n",
    "frequency_bands = [(4, 8), (8, 12), (12, 16), (16, 20), (20, 24), (24, 28), (28, 32), (32, 36), (36, 40)]\n",
    "\n",
    "# Apply bandpass filter for each frequency band\n",
    "X_train_filt = np.array([bandpass_filter(X_train, low, high, fs=1000) for (low, high) in frequency_bands])\n",
    "X_val_filt = np.array([bandpass_filter(X_val, low, high, fs=1000) for (low, high) in frequency_bands])\n",
    "X_test_filt = np.array([bandpass_filter(X_test, low, high, fs=1000) for (low, high) in frequency_bands])\n",
    "\n",
    "# Reshape to combine frequency bands\n",
    "# New shape: (trials, channels, samples, frequency_bands)\n",
    "X_train_filt = np.transpose(X_train_filt, (1, 2, 3, 0))\n",
    "X_val_filt = np.transpose(X_val_filt, (1, 2, 3, 0))\n",
    "X_test_filt = np.transpose(X_test_filt, (1, 2, 3, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, BatchNormalization, AveragePooling2D, Dropout, Flatten, Dense, Lambda\n",
    "\n",
    "# Define the TA-CSPNN model with a corrected activation function\n",
    "model = Sequential([\n",
    "    # Temporal Convolution\n",
    "    Conv2D(filters=8, kernel_size=(1, 63), padding='same', input_shape=(n_channels, n_samples, len(frequency_bands))),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    # Spatial Convolution (Depthwise)\n",
    "    DepthwiseConv2D(kernel_size=(n_channels, 1), depth_multiplier=2, depthwise_constraint=tf.keras.constraints.max_norm(1.)),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    # Custom Squaring Activation\n",
    "    Lambda(lambda x: tf.math.square(x)),  # Square activation function\n",
    "    \n",
    "    # Average Pooling\n",
    "    AveragePooling2D(pool_size=(1, n_samples)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    # Flatten and Fully Connected Layer\n",
    "    Flatten(),\n",
    "    Dense(units=4, activation='softmax')  # Assuming 4 classes for motor imagery\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels from (-1, 1) to (0, 1)\n",
    "Y_train = (Y_train + 1) // 2  # Convert -1 -> 0 and 1 -> 1\n",
    "Y_val = (Y_val + 1) // 2\n",
    "Y_test = (Y_test + 1) // 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5s/step - accuracy: 0.3996 - loss: 1.2914 - val_accuracy: 0.4464 - val_loss: 1.6084\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4s/step - accuracy: 0.4896 - loss: 1.2964 - val_accuracy: 0.5536 - val_loss: 1.3844\n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4782 - loss: 1.2665 - val_accuracy: 0.5357 - val_loss: 1.2872\n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5242 - loss: 1.2247 - val_accuracy: 0.5179 - val_loss: 1.2665\n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4s/step - accuracy: 0.5138 - loss: 1.2271 - val_accuracy: 0.4821 - val_loss: 1.3534\n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5286 - loss: 1.2979 - val_accuracy: 0.4821 - val_loss: 1.3465\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4s/step - accuracy: 0.4541 - loss: 1.3447 - val_accuracy: 0.4821 - val_loss: 1.3394\n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5352 - loss: 1.3375 - val_accuracy: 0.4821 - val_loss: 1.3324\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5196 - loss: 1.3302 - val_accuracy: 0.4821 - val_loss: 1.3254\n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5153 - loss: 1.3230 - val_accuracy: 0.4821 - val_loss: 1.3184\n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5s/step - accuracy: 0.4900 - loss: 1.3158 - val_accuracy: 0.4821 - val_loss: 1.3114\n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5201 - loss: 1.3086 - val_accuracy: 0.4821 - val_loss: 1.3042\n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5065 - loss: 1.3015 - val_accuracy: 0.4821 - val_loss: 1.2971\n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5035 - loss: 1.2944 - val_accuracy: 0.4821 - val_loss: 1.2901\n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5402 - loss: 1.2870 - val_accuracy: 0.4821 - val_loss: 1.2830\n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5268 - loss: 1.2799 - val_accuracy: 0.4821 - val_loss: 1.2759\n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5075 - loss: 1.2729 - val_accuracy: 0.4821 - val_loss: 1.2683\n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.5059 - loss: 1.2656 - val_accuracy: 0.4821 - val_loss: 1.2610\n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5412 - loss: 1.2594 - val_accuracy: 0.4821 - val_loss: 1.2535\n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4940 - loss: 1.2509 - val_accuracy: 0.4821 - val_loss: 1.2465\n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5043 - loss: 1.2441 - val_accuracy: 0.4821 - val_loss: 1.2391\n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5737 - loss: 1.2353 - val_accuracy: 0.4821 - val_loss: 1.2320\n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4779 - loss: 1.2303 - val_accuracy: 0.4821 - val_loss: 1.2241\n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5242 - loss: 1.2212 - val_accuracy: 0.4821 - val_loss: 1.2162\n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4847 - loss: 1.2156 - val_accuracy: 0.4821 - val_loss: 1.2092\n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4612 - loss: 1.2096 - val_accuracy: 0.4821 - val_loss: 1.2028\n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4753 - loss: 1.1993 - val_accuracy: 0.4821 - val_loss: 1.1970\n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5001 - loss: 1.1910 - val_accuracy: 0.4821 - val_loss: 1.1903\n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4805 - loss: 1.1841 - val_accuracy: 0.4821 - val_loss: 1.1819\n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5593 - loss: 1.1741 - val_accuracy: 0.4821 - val_loss: 1.1718\n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4999 - loss: 1.1682 - val_accuracy: 0.4821 - val_loss: 1.1637\n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.4983 - loss: 1.1600 - val_accuracy: 0.4821 - val_loss: 1.1565\n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.5207 - loss: 1.1522 - val_accuracy: 0.4821 - val_loss: 1.1471\n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4s/step - accuracy: 0.5140 - loss: 1.1385 - val_accuracy: 0.4821 - val_loss: 1.1373\n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4854 - loss: 1.1383 - val_accuracy: 0.4821 - val_loss: 1.1261\n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5003 - loss: 1.1237 - val_accuracy: 0.4821 - val_loss: 1.1172\n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.5515 - loss: 1.1138 - val_accuracy: 0.4821 - val_loss: 1.1080\n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5132 - loss: 1.1090 - val_accuracy: 0.4821 - val_loss: 1.0982\n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5s/step - accuracy: 0.5185 - loss: 1.1020 - val_accuracy: 0.4821 - val_loss: 1.0912\n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5100 - loss: 1.0903 - val_accuracy: 0.4821 - val_loss: 1.0874\n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.4903 - loss: 1.0840 - val_accuracy: 0.4821 - val_loss: 1.0838\n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5265 - loss: 1.0737 - val_accuracy: 0.4821 - val_loss: 1.0790\n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.5735 - loss: 1.0634 - val_accuracy: 0.4821 - val_loss: 1.0718\n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4875 - loss: 1.0537 - val_accuracy: 0.4821 - val_loss: 1.0642\n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5020 - loss: 1.0496 - val_accuracy: 0.4821 - val_loss: 1.0576\n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5244 - loss: 1.0388 - val_accuracy: 0.4821 - val_loss: 1.0485\n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5257 - loss: 1.0340 - val_accuracy: 0.4821 - val_loss: 1.0387\n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4940 - loss: 1.0188 - val_accuracy: 0.4821 - val_loss: 1.0274\n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.5316 - loss: 1.0102 - val_accuracy: 0.4821 - val_loss: 1.0184\n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4794 - loss: 1.0107 - val_accuracy: 0.4821 - val_loss: 1.0105\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.5277 - loss: 0.9976 - val_accuracy: 0.4821 - val_loss: 1.0030\n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4642 - loss: 0.9958 - val_accuracy: 0.4821 - val_loss: 0.9897\n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4926 - loss: 0.9941 - val_accuracy: 0.4821 - val_loss: 0.9815\n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4871 - loss: 0.9797 - val_accuracy: 0.4821 - val_loss: 0.9769\n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4992 - loss: 0.9632 - val_accuracy: 0.4821 - val_loss: 0.9718\n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4606 - loss: 0.9698 - val_accuracy: 0.4821 - val_loss: 0.9694\n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5s/step - accuracy: 0.5689 - loss: 0.9424 - val_accuracy: 0.4821 - val_loss: 0.9607\n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5373 - loss: 0.9419 - val_accuracy: 0.4821 - val_loss: 0.9492\n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4s/step - accuracy: 0.4717 - loss: 0.9379 - val_accuracy: 0.4821 - val_loss: 0.9349\n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4872 - loss: 0.9297 - val_accuracy: 0.4821 - val_loss: 0.9245\n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5236 - loss: 0.9320 - val_accuracy: 0.4821 - val_loss: 0.9206\n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4979 - loss: 0.9150 - val_accuracy: 0.4821 - val_loss: 0.9227\n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.5067 - loss: 0.9192 - val_accuracy: 0.4821 - val_loss: 0.9171\n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5049 - loss: 0.9163 - val_accuracy: 0.4821 - val_loss: 0.9157\n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4789 - loss: 0.9063 - val_accuracy: 0.4821 - val_loss: 0.9134\n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5061 - loss: 0.8936 - val_accuracy: 0.4821 - val_loss: 0.8994\n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4719 - loss: 0.8880 - val_accuracy: 0.4821 - val_loss: 0.8871\n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5s/step - accuracy: 0.4944 - loss: 0.8705 - val_accuracy: 0.4821 - val_loss: 0.8729\n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4883 - loss: 0.8719 - val_accuracy: 0.4821 - val_loss: 0.8620\n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5246 - loss: 0.8748 - val_accuracy: 0.4821 - val_loss: 0.8467\n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4830 - loss: 0.8634 - val_accuracy: 0.4821 - val_loss: 0.8391\n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4628 - loss: 0.8651 - val_accuracy: 0.4821 - val_loss: 0.8289\n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.5928 - loss: 0.8431 - val_accuracy: 0.4821 - val_loss: 0.8188\n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5021 - loss: 0.8388 - val_accuracy: 0.4821 - val_loss: 0.8118\n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5290 - loss: 0.8350 - val_accuracy: 0.4821 - val_loss: 0.8070\n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.5246 - loss: 0.8510 - val_accuracy: 0.4821 - val_loss: 0.8045\n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.4576 - loss: 0.8400 - val_accuracy: 0.4821 - val_loss: 0.8078\n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.4155 - loss: 0.8495 - val_accuracy: 0.4821 - val_loss: 0.8128\n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.4830 - loss: 0.8335 - val_accuracy: 0.4821 - val_loss: 0.8129\n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.5050 - loss: 0.8271 - val_accuracy: 0.4821 - val_loss: 0.8150\n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.4951 - loss: 0.8192 - val_accuracy: 0.4821 - val_loss: 0.8200\n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4s/step - accuracy: 0.4863 - loss: 0.8179 - val_accuracy: 0.4821 - val_loss: 0.8156\n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4s/step - accuracy: 0.4834 - loss: 0.8214 - val_accuracy: 0.4821 - val_loss: 0.8029\n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.4689 - loss: 0.8139 - val_accuracy: 0.4821 - val_loss: 0.7951\n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.4834 - loss: 0.8029 - val_accuracy: 0.4821 - val_loss: 0.7912\n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.4536 - loss: 0.8086 - val_accuracy: 0.4821 - val_loss: 0.7875\n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.5256 - loss: 0.8037 - val_accuracy: 0.4821 - val_loss: 0.7810\n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.4580 - loss: 0.8188 - val_accuracy: 0.4821 - val_loss: 0.7765\n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.5093 - loss: 0.7991 - val_accuracy: 0.4821 - val_loss: 0.7704\n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.4802 - loss: 0.8035 - val_accuracy: 0.4821 - val_loss: 0.7647\n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.4639 - loss: 0.8033 - val_accuracy: 0.4821 - val_loss: 0.7596\n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.4702 - loss: 0.7918 - val_accuracy: 0.4821 - val_loss: 0.7606\n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.4916 - loss: 0.7868 - val_accuracy: 0.4821 - val_loss: 0.7596\n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.4796 - loss: 0.7930 - val_accuracy: 0.4821 - val_loss: 0.7545\n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.5010 - loss: 0.7772 - val_accuracy: 0.4821 - val_loss: 0.7517\n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.5219 - loss: 0.7807 - val_accuracy: 0.4821 - val_loss: 0.7456\n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.5177 - loss: 0.7765 - val_accuracy: 0.4821 - val_loss: 0.7444\n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.5694 - loss: 0.7586 - val_accuracy: 0.4821 - val_loss: 0.7458\n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.5135 - loss: 0.7689 - val_accuracy: 0.4821 - val_loss: 0.7433\n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.4372 - loss: 0.7893 - val_accuracy: 0.4821 - val_loss: 0.7366\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 484ms/step - accuracy: 0.5135 - loss: 0.7333\n",
      "Adaptation Test Accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_filt, Y_train, epochs=100, batch_size=32, validation_data=(X_val_filt, Y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test_filt, Y_test)\n",
    "print(f'Adaptation Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earnings_transcript_scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
